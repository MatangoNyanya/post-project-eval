# Auto-generated from 17_check_digit.ipynb
# Do not edit this file directly; edit the notebook instead.

# %%

import pandas as pd

# %%

df = pd.read_csv("df_check_3.csv",index_col=0)
df

# %%

# -*- coding: utf-8 -*-
# 監査テーブル作成スクリプト（貼り付けてそのまま実行可）
# - 「プロジェクトコスト_計画時」「プロジェクトコスト_実績」両対応
# - USD→JPYは 1 USD = 150 円（既定、変更可）
# - 和の複合単位（例: 2億5195万8千円）を総和で解釈
# - USDでも和単位（億/百万/万/千）や英語単位（billion/million/k）を許容

import re
import math
import unicodedata
import numpy as np
import pandas as pd

# =========================
# 設定（必要に応じて調整）
# =========================
USD_TO_JPY = 150.0
OK_RATIO_LOW, OK_RATIO_HIGH = 0.80, 1.25  # OK帯
NEAR_10_LOW, NEAR_10_HIGH   = 7.5, 12.5   # ×10疑い
NEAR_100_LOW, NEAR_100_HIGH = 75, 125     # ×100疑い
NEAR_01_LOW, NEAR_01_HIGH   = 0.075, 0.125  # ×0.1疑い
NEAR_001_LOW, NEAR_001_HIGH = 0.0075, 0.0125  # ×0.01疑い

# =========================
# ユーティリティ
# =========================
def _to_halfwidth_lower(s: str) -> str:
    s = unicodedata.normalize("NFKC", str(s))
    s = s.lower()
    # 通貨表記のゆれを正規化
    s = re.sub(r"米ドル", "usd", s)
    s = re.sub(r"u\.?s\.?\s*ドル", "usd", s)   # u.s.ドル / us ドル
    s = re.sub(r"usドル", "usd", s)
    s = re.sub(r"us\$", "usd", s)
    s = re.sub(r"\$", "usd", s)
    # 「ドル」単独もUSD扱い（他通貨を導入するならここを調整）
    s = re.sub(r"ドル", "usd", s)
    s = re.sub(r"\s+", " ", s).strip()
    return s

def _is_missing(x) -> bool:
    if x is None:
        return True
    s = str(x).strip()
    return s == "" or s.upper() == "N/A"

def _clean_numeric_like(x):
    """'320,000,000' → 320000000.0 のように、数字・小数点・符号のみ残してfloat化"""
    if _is_missing(x):
        return np.nan
    s = str(x)
    s = re.sub(r"[^\d\.\-]", "", s)
    if s in ("", "-", ".", "-.", ".-"):
        return np.nan
    try:
        return float(s)
    except Exception:
        return np.nan

def _has_range_or_approx(text_norm: str) -> bool:
    if re.search(r"(約|およそ|前後|程度)", text_norm):
        return True
    nums = re.findall(r"\d+(?:,\d{3})*(?:\.\d+)?", text_norm)
    return len(nums) >= 2 and re.search(r"[~〜～\-–—－]", text_norm)

def _detect_currency(text_norm: str):
    has_usd = bool(re.search(r"(?<![a-z0-9])usd(?![a-z0-9])", text_norm))
    has_jpy = bool(re.search(r"[¥￥]|円", text_norm))
    if has_usd and not has_jpy:
        return "USD", False
    if has_jpy and not has_usd:
        return "JPY", False
    if has_usd and has_jpy:
        return "JPY", True
    if re.search(r"(兆|億|万|千|円)", text_norm):
        return "JPY", False
    return "UNKNOWN", False

# ===== 単位テーブル =====
_JA_UNITS = [
    ("千億", 1e11),
    ("百億", 1e10),
    ("十億", 1e9),
    ("兆",   1e12),
    ("億",   1e8),
    ("千万円", 1e7), ("千万", 1e7),
    ("百万円", 1e6), ("百万", 1e6),
    ("十万円", 1e5), ("十万", 1e5),
    ("万円", 1e4),   ("万",   1e4),
    ("千円", 1e3),
    ("千",   1e3),
    ("円",   1.0),
]
# 長い表記を優先してマッチさせるため、長さでソートしてからALTを作る
_JA_UNIT_MAP = dict(_JA_UNITS)
_JA_UNITS_SORT = sorted([u for u, _ in _JA_UNITS], key=len, reverse=True)
_JA_UNIT_ALT = "|".join(map(re.escape, _JA_UNITS_SORT))

_EN_UNITS = {
    "billion": 1e9, "bn": 1e9,
    "million": 1e6, "mn": 1e6,
    "thousand": 1e3, "k": 1e3,
}

_RE_JA_SEG = re.compile(
    rf"(?P<num>\d{{1,3}}(?:,\d{{3}})*(?:\.\d+)?|\d+(?:\.\d+)?)(?P<unit>{_JA_UNIT_ALT})"
)
_RE_EN_SEG = re.compile(
    r"(?P<num>\d{1,3}(?:,\d{3})*(?:\.\d+)?|\d+(?:\.\d+)?)\s*(?P<unit>billion|bn|million|mn|thousand|k)\b"
)

def _parse_ja_segments(text_norm: str):
    """和の単位（複合）を加算。JPYのときは円スケール、USDのときはドルスケールとして扱う。"""
    total = 0.0
    segs = []
    for m in _RE_JA_SEG.finditer(text_norm):
        num = float(m.group("num").replace(",", ""))
        unit = m.group("unit")
        factor = _JA_UNIT_MAP[unit]
        val = num * factor
        total += val
        segs.append({"num": num, "unit": unit, "factor": factor, "value": val})
    return (np.nan if not segs else total), segs

def _parse_en_segments(text_norm: str):
    """英語単位（billion/million/thousand/k）を加算（ドル基準）"""
    total = 0.0
    segs = []
    for m in _RE_EN_SEG.finditer(text_norm):
        num = float(m.group("num").replace(",", ""))
        unit = m.group("unit")
        factor = _EN_UNITS[unit]
        val = num * factor
        total += val
        segs.append({"num": num, "unit": unit, "factor": factor, "value": val})
    return (np.nan if not segs else total), segs

def _extract_plain_number(text_norm: str):
    m = re.search(r"\d+(?:,\d{3})*(?:\.\d+)?", text_norm)
    if not m:
        return np.nan
    return float(m.group(0).replace(",", ""))

def parse_money_to_jpy(text_raw, usd_rate: float = USD_TO_JPY):
    """
    金額テキスト → 円換算の期待値
      - 和の複合単位（例: 2億5195万8千円）を総和
      - USDでも和単位（億/百万/万/千）や英語単位（billion/million/k）を許容
      - 範囲/約表記はフラグ付け（値は算出）、監査側で要確認に回す
    戻り: expected_jpy (float), meta (dict)
    """
    meta = {
        "text_normalized": None,
        "currency": None,
        "currency_conflict": False,
        "ja_segments": [],
        "en_segments": [],
        "number_extracted_plain": None,
        "flags": [],
        "currency_rate": None,
    }

    if _is_missing(text_raw):
        meta["flags"].append("missing_text")
        return np.nan, meta

    text_norm = _to_halfwidth_lower(text_raw)
    meta["text_normalized"] = text_norm

    if _has_range_or_approx(text_norm):
        meta["flags"].append("range_or_approx")

    currency, conflict = _detect_currency(text_norm)
    meta["currency"] = currency
    meta["currency_conflict"] = conflict

    ja_total, ja_segs = _parse_ja_segments(text_norm)
    en_total, en_segs = _parse_en_segments(text_norm)
    meta["ja_segments"] = ja_segs
    meta["en_segments"] = en_segs

    expected = np.nan

    if currency == "JPY":
        if not np.isnan(ja_total):
            expected = float(ja_total)
        else:
            plain = _extract_plain_number(text_norm)
            meta["number_extracted_plain"] = plain
            if not np.isnan(plain):
                expected = float(plain)  # 単位なし→円と仮定
        meta["currency_rate"] = 1.0

    elif currency == "USD":
        total_usd = 0.0
        used = False
        if not np.isnan(ja_total):  # 和単位でもドルスケールとして解釈（例：19億usd）
            total_usd += ja_total
            used = True
        if not np.isnan(en_total):  # 英語単位
            total_usd += en_total
            used = True
        if used:
            expected = float(total_usd * usd_rate)
            meta["currency_rate"] = usd_rate
        else:
            plain = _extract_plain_number(text_norm)
            meta["number_extracted_plain"] = plain
            if not np.isnan(plain):
                expected = float(plain * usd_rate)
                meta["currency_rate"] = usd_rate

    else:
        meta["flags"].append("unknown_currency")

    if np.isnan(expected):
        meta["flags"].append("parse_failed")

    if meta["currency_conflict"]:
        meta["flags"].append("currency_conflict")

    return expected, meta

def _classify_ratio(r: float) -> str:
    if r is None or np.isnan(r) or r <= 0:
        return "UNDECIDABLE"
    if OK_RATIO_LOW <= r <= OK_RATIO_HIGH:
        return "OK"
    if NEAR_10_LOW <= r <= NEAR_10_HIGH:
        return "SUSPECT_X10"
    if NEAR_100_LOW <= r <= NEAR_100_HIGH:
        return "SUSPECT_X100"
    if NEAR_01_LOW <= r <= NEAR_01_HIGH:
        return "SUSPECT_X0.1"
    if NEAR_001_LOW <= r <= NEAR_001_HIGH:
        return "SUSPECT_X0.01"
    return "MISMATCH"

def _robust_z_mad(x: pd.Series) -> pd.Series:
    """対数値などに対してロバストZ（MAD法）を返す。MAD=0の時はNaN。"""
    x = x.astype(float)
    med = np.nanmedian(x)
    mad = np.nanmedian(np.abs(x - med))
    if mad == 0 or np.isnan(mad):
        return pd.Series(np.full(len(x), np.nan), index=x.index)
    return 0.6745 * (x - med) / mad

def _severity_order(label: str) -> int:
    order = {
        "SUSPECT_X100": 0,
        "SUSPECT_X10": 1,
        "SUSPECT_X0.01": 2,
        "SUSPECT_X0.1": 3,
        "MISMATCH": 4,
        "UNDECIDABLE": 5,
        "OK": 9,
    }
    return order.get(label, 8)

def audit_cost_column(
    df: pd.DataFrame,
    text_col: str,
    int_col: str,
    usd_rate: float = USD_TO_JPY,
    context_cols: list = None,
) -> pd.DataFrame:
    """
    単一の金額カラム（テキスト＋_int）について監査テーブルを作成
      - context_cols: 監査テーブルへそのまま持ち込む文脈列（ID/国名/評価年度など）
    """
    context_cols = context_cols or []
    out_rows = []

    df[text_col] = df[text_col].str.replace(" ", "", regex=True)
    df[text_col] = df[text_col].str.replace("約", "", regex=True)

    int_series = df[int_col].apply(_clean_numeric_like) if int_col in df.columns else pd.Series(np.nan, index=df.index)
    text_series = df[text_col] if text_col in df.columns else pd.Series("", index=df.index)

    for i, (text_raw, int_val) in enumerate(zip(text_series, int_series)):
        expected_jpy, meta = parse_money_to_jpy(text_raw, usd_rate=usd_rate)
        ratio = (int_val / expected_jpy) if (not np.isnan(int_val) and not np.isnan(expected_jpy) and expected_jpy != 0) else np.nan
        label = _classify_ratio(ratio)

        reasons = []
        if "missing_text" in meta["flags"]:
            reasons.append("テキスト欠損")
        if "range_or_approx" in meta["flags"]:
            reasons.append("範囲/約表記→要確認")
        if "unknown_currency" in meta["flags"]:
            reasons.append("通貨不明→要確認")
        if "currency_conflict" in meta["flags"]:
            reasons.append("通貨表記衝突→要確認")
        if "parse_failed" in meta["flags"]:
            reasons.append("数値/単位の解析失敗→要確認")
        if label != "OK" and not np.isnan(ratio):
            reasons.append(f"比率= {ratio:.3f} → {label}")
        if label == "UNDECIDABLE":
            reasons.append("比率判定不可")

        row = {
            "元index": df.index[i],
            "行番号": i,
            "対象カラム": text_col,
            "テキスト原文": text_raw,
            "正規化テキスト": meta["text_normalized"],
            "検出通貨": meta["currency"],
            "為替適用": meta["currency_rate"],
            "和単位セグメント": str(meta["ja_segments"]),
            "英単位セグメント": str(meta["en_segments"]),
            "期待値_JPY": expected_jpy,
            f"{int_col}_raw": df.iloc[i][int_col] if int_col in df.columns else np.nan,
            f"{int_col}_num": int_val,
            "比率_int/期待": ratio,
            "判定": label,
            "疑い理由": " / ".join(reasons) if reasons else "",
        }

        for c in context_cols:
            row[c] = df.iloc[i][c] if c in df.columns else np.nan

        out_rows.append(row)

    out = pd.DataFrame(out_rows)

    # 分布外れ値（参考）
    if f"{int_col}_num" in out.columns:
        with np.errstate(divide='ignore', invalid='ignore'):
            out["log10_int"] = np.where(out[f"{int_col}_num"] > 0, np.log10(out[f"{int_col}_num"]), np.nan)
        out["robust_z_int"] = _robust_z_mad(out["log10_int"])
        out["分布外れ値_flag(abs_z>3.5)"] = out["robust_z_int"].abs() > 3.5

    # 重要度順に並べ替え（×100→×10→…→MISMATCH→判定不可→OK）
    out["severity_rank"] = out["判定"].apply(_severity_order)

    def _dev_from1(r):
        try:
            return abs(math.log10(r))
        except Exception:
            return np.nan

    out["dev_from_1"] = out["比率_int/期待"].apply(_dev_from1)
    out = out.sort_values(by=["severity_rank", "dev_from_1"], ascending=[True, False]).reset_index(drop=True)
    return out.drop(columns=["severity_rank", "dev_from_1"])

def build_costs_audit(
    df: pd.DataFrame,
    usd_rate: float = USD_TO_JPY,
    context_cols: list = None,
    suspicious_only: bool = True,
) -> pd.DataFrame:
    """
    2列（計画時/実績）をまとめて監査テーブル化
      - suspicious_only=True: OK以外＋要確認（解析失敗/範囲/通貨不明/衝突）だけ抽出
      - context_cols: ["プロジェクト期","国名","評価年度","評価会社","評価者"] など識別用列
    """
    context_cols = context_cols or ["プロジェクト期", "国名", "評価年度", "評価会社", "評価者"]
    parts = []

    parts.append(
        audit_cost_column(
            df,
            text_col="プロジェクトコスト_計画時",
            int_col="プロジェクトコスト_計画時_int",
            usd_rate=usd_rate,
            context_cols=context_cols,
        )
    )
    parts.append(
        audit_cost_column(
            df,
            text_col="プロジェクトコスト_実績",
            int_col="プロジェクトコスト_実績_int",
            usd_rate=usd_rate,
            context_cols=context_cols,
        )
    )

    audit = pd.concat(parts, axis=0, ignore_index=True)

    if suspicious_only:
        mask = (
            (audit["判定"] != "OK") |
            audit["疑い理由"].str.contains("要確認|解析失敗|衝突", na=False)
        )
        audit = audit.loc[mask].reset_index(drop=True)

    return audit

# %%

audit_df = build_costs_audit(
    df,
    usd_rate=150.0,                      # 1 USD = 150円
    context_cols=["file"],
    suspicious_only=False                 
)

# %%

audit_df.to_csv("audit_costs_suspect.csv", index=False)

# %%

audit_df.head(3)

# %%

# 判定結果確認
audit_df.groupby('判定').agg({'file':'count'})

# %%

audit_df.columns

# %%

cols=['対象カラム', 'テキスト原文', 'プロジェクトコスト_計画時_int_raw','プロジェクトコスト_実績_int_raw','期待値_JPY','疑い理由', 'file']
# 誤検知なので修正不要
audit_df[audit_df['判定']=='MISMATCH'][cols]

# %%

# １０００億が100億になっているため修正必要
audit_df[audit_df['判定']=='SUSPECT_X0.1'][cols]

# %%

# １０億が100億になっているため修正必要
audit_df[audit_df['判定']=='SUSPECT_X10'][cols]

# %%

# NaNのため修正不可能
audit_df[audit_df['判定']=='UNDECIDABLE'][cols]

# %%

# 修正対象のみ抽出
except_type=['MISMATCH','OK','UNDECIDABLE']
fix_target = audit_df[~audit_df['判定'].isin(except_type)]
fix_target

# %%

import numpy as np
import pandas as pd

def append_fix_suggestions(audit_df: pd.DataFrame) -> pd.DataFrame:
    """
    監査テーブル(audit_df)に以下の列を追加して返す:
      - 修正対象_int_col: どの _int 列を直す想定か
      - 現行_int_num: 現在の数値（_num）
      - 修正倍率: SUSPECT_* に応じた倍率（例: ×10疑い→0.1）
      - 修正案_num: 倍率適用 or 期待値_JPY（MISMATCH時）
      - 修正案_書式: 3桁区切りの文字列
      - 修正案_根拠: 提案根拠
      - 修正後_比率_int/期待: 修正案 / 期待値_JPY
    """
    df = audit_df.copy()

    # どの _int を直す列かを決める（対象カラムに基づく）
    df["修正対象_int_col"] = np.where(
        df["対象カラム"].eq("プロジェクトコスト_計画時"),
        "プロジェクトコスト_計画時_int_num",
        np.where(
            df["対象カラム"].eq("プロジェクトコスト_実績"),
            "プロジェクトコスト_実績_int_num",
            np.nan
        )
    )

    # 現行の数値（_num）を横持ちから1列にまとめる
    # ここでは union されている2列のうち、行に対応する方を選択
    df["現行_int_num"] = np.where(
        df["対象カラム"].eq("プロジェクトコスト_計画時"),
        df.get("プロジェクトコスト_計画時_int_num"),
        np.where(
            df["対象カラム"].eq("プロジェクトコスト_実績"),
            df.get("プロジェクトコスト_実績_int_num"),
            np.nan
        )
    )

    # 判定→修正倍率のマップ
    label_to_factor = {
        "SUSPECT_X10": 0.1,     # ×10 の疑い → /10
        "SUSPECT_X100": 0.01,   # ×100 の疑い → /100
        "SUSPECT_X0.1": 10.0,   # ×0.1 の疑い → ×10
        "SUSPECT_X0.01": 100.0  # ×0.01 の疑い → ×100
    }
    df["修正倍率"] = df["判定"].map(label_to_factor)

    # 倍率が出た行は「現行×修正倍率」、MISMATCHはテキスト換算の期待値を提案
    df["修正案_num"] = np.where(
        df["修正倍率"].notna() & df["現行_int_num"].notna(),
        df["現行_int_num"] * df["修正倍率"],
        np.where(
            df["判定"].eq("MISMATCH") & df["期待値_JPY"].notna(),
            df["期待値_JPY"],
            np.nan
        )
    ).round(0)

    # 3桁区切りの見やすい表記
    df["修正案_書式"] = df["修正案_num"].map(lambda x: f"{int(x):,}" if pd.notna(x) else "")

    # 根拠テキスト
    def _reason(row):
        if pd.notna(row["修正倍率"]):
            return f"{row['判定']}のため 現行値×{row['修正倍率']}"
        if row["判定"] == "MISMATCH" and pd.notna(row["期待値_JPY"]):
            return "テキスト換算の期待値（期待値_JPY）に一致させる提案"
        return ""
    df["修正案_根拠"] = df.apply(_reason, axis=1)

    # 修正後に期待値と合うかの目安
    df["修正後_比率_int/期待"] = np.where(
        df["修正案_num"].notna() & df["期待値_JPY"].notna() & (df["期待値_JPY"] != 0),
        df["修正案_num"] / df["期待値_JPY"],
        np.nan
    )

    return df

# %%

# 追加提案列を付与:
fix_target = append_fix_suggestions(fix_target)

# %%

fix_target

# %%

df_ori = df.copy()

# %%

# 1000億に修正
df[df['file']=='https://www2.jica.go.jp/ja/evaluation/pdf/2019_ID-P171_4_f.pdf'][['プロジェクトコスト_計画時','プロジェクトコスト_計画時_int']]

# %%

url = "https://www2.jica.go.jp/ja/evaluation/pdf/2019_ID-P171_4_f.pdf"
mask = df['file'].eq(url)
df.loc[mask, 'プロジェクトコスト_計画時_int'] = 306809000000
df.loc[mask, ['プロジェクトコスト_計画時', 'プロジェクトコスト_計画時_int']]

# %%

# 10億に修正
df[df['file']=='https://www2.jica.go.jp/ja/evaluation/pdf/2020_0960980_4_f.pdf'][['プロジェクトコスト_実績','プロジェクトコスト_実績_int']]

# %%

url = "https://www2.jica.go.jp/ja/evaluation/pdf/2020_0960980_4_f.pdf"
mask = df['file'].eq(url)
df.loc[mask, 'プロジェクトコスト_実績_int'] = 6994000000
df.loc[mask, ['プロジェクトコスト_実績', 'プロジェクトコスト_実績_int']]

# %%

# 10億に修正
df[df['file']=='https://www2.jica.go.jp/ja/evaluation/pdf/2021_1202321_4_f.pdf'][['プロジェクトコスト_実績','プロジェクトコスト_実績_int']]

# %%

df.loc[203, 'プロジェクトコスト_実績_int'] = 4799000000
df[df['file']=='https://www2.jica.go.jp/ja/evaluation/pdf/2021_1202321_4_f.pdf'][['プロジェクトコスト_実績','プロジェクトコスト_実績_int']]

# %%

# 1000億に修正
df[df['file']=='https://www2.jica.go.jp/ja/evaluation/pdf/2019_ID-P171_4_f.pdf'][['プロジェクトコスト_実績','プロジェクトコスト_実績_int']]

# %%

df.loc[1302, 'プロジェクトコスト_実績_int'] = 235498000000
df[df['file']=='https://www2.jica.go.jp/ja/evaluation/pdf/2019_ID-P171_4_f.pdf'][['プロジェクトコスト_実績','プロジェクトコスト_実績_int']]

# %%

fix_target.columns

# %%

cols = ['プロジェクトコスト_計画時','プロジェクトコスト_計画時_int','プロジェクトコスト_実績','プロジェクトコスト_実績_int']

# %%

#修正前
df_ori[df_ori['file'].isin(fix_target['file'].tolist())][cols]

# %%

#修正後
df[df['file'].isin(fix_target['file'].tolist())][cols]

# %%

# 保存
df.to_csv('df_check_4.csv')

# %%


# %%


# %%


# %%


# %%


# %%

